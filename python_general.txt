Args: positional or keyword
	def fn(positional_only_args, /, positional_or_keyword, *, keyword_only):

	
Ternary:
	a if a < b else b


f-string (f"...{var}..."
   f"{var=}"	# var=10
   f"{var%2=}"	# var%2=0
   f"{var=:FORMAT_STRING}"	# format string is related to type. Invokes __format__ method of class/type
   	f"{now=:%y-%m-%d}"
   	f"{float_number=:.2f}"
   f"{var!a}"	# !a -> ascii (converts non-ascii e.g. unicode into \U)
   f"{var!r}"	# !r -> print repr equivalent
   f"{var!s}"	# !s -> print str (default) 

   
Size of:
   import sys
   sys.getsizeof([0,1,2,3])	# bytes used by this data struct - does not count recursive data structs, only 1 level deep. Custom code to do recusrive size computation. 
   				# Object has ref.count + ptr.to.its.type at least + 2ptr for garbage collector ... all of which getsizeof() captures.
   
   PyObject has:
   	ob_refcount  
   	ob_type
   PyVarObject has:
   	ob_size		# len - actual size
   PyListObject has:
   	ob_item		# pointer
   	allocated	# how many elem "could" fit in ob_item memory - max size (returned by getsizeof)
   2 Garbage collection pointers
   So a list has 7 meta-data elements. Size of empty list = 7 * 8 = 56 bytes


__slots__ can be used to save memory taken by objects + restrict from adding more member variable (obj.NewVar). 
The instance loses __dicts__.
The class retains __dicts__ and gains additional __slots__ member along with descriptors to get/set these slots members implemented in C code to access member based on memory location (instead of __dict__). 
	obj.slotX = 'some value' 	# calls Class.__dict__['slotX'].__set__(obj, 'some_value'
	print(obj.slotX)		# calls Class.__dict__['slotX'].__get__(obj, Class)


Profilers are of 2 types (a) Tracing which have higher initial setup but very accurate reporting (b) Sampling
cProfile is tracing type; scalene are sampler type which also supports (threads, multiprocessing, Python vs C time, GPU, mem.trend, mem.leaks, copy time between python/native library)
Profile with cProfile module:
   $ python3 -m cProfile mycode.py    # simple/basic
   $ python3 -m cProfile -o mycode.prof mycode.py && snakeviz mycode.prof

   import cProfile
   import pstats
   with cProfile.Profile() as profiler:
       my_function()
   stats = pstats.Stats(profiler)
   stats.sort_stats(pstats.SortKey.TIME).
   # stats.print_stats()		# alternatel, pip install snakeviz
   stats.dump_stats(filename='code_profile.prof')
   
   $ snakeviz code_profile.prof
   
Profiling with scalene:
   $ scalene [options] mycode.py   
   	options:
   	 --reduced-profile (only show where code runs for atleast 1%)
   	 --html --outfile profile.html  (line, fn level profile)
   	 --cpu-only	(not memory but does GPU also)
   	
   
   
Benchmarking:
    1. set PYTHONDONTWRITEBYTECODE=1		# don't cache bytecode between test runs
    2. python -m timeit -s "from mymodule import function" "function()"		# -s part not included in benchmark time
    3. 
    P

Faster code tips:
   - use itertools/collections e.g. count() instead of loops with var increment
   - speed vs memory trade off (generator vs list) esp if only first elelement of list is needed then next(gen)
   - numpy/numba
   - code optimization e.g. right data struct/algorithm
   	- e.g. {}, [], () faster than dict(), list(), tuple() fn calls. Tuple faster than list
   	- unique elements of list while retaining order dict.fromkeys(mylist) but elements need to be hashable
   	- DRY vs calling too many fn (overheads).
   	- look for loop-invariant stmt (can be done out of loop), use comprehensions, correct data struct(tuple, frozenset, str, bytes, list/bytearray, set, dict)
   
   
Data containers : Class/DataClass/Dict/NamedTuple
	class Pet(typing.NamedTuple):		# Pure classes faster than dataclass (50%) & namedtuple (25%)! but more code. Classes similar to dict.
	   legs:int
	   noise:str 

	@dataclass
	class Pet:
	   legs:int
	   noise:str

	Pet = namedtuple("Pet","legs noise")


Dataclasses: provides __init__, __repr__ and __eq__ by default. 

from dataclasses import dataclass, field, astuple, asdict
import inspect

@dataclass(frozen=True, order=True)			# order provides le/ge/lt/gt, frozen allows obj value to NOT be modified after initializations. 
							# Others: kw_args=True, match=True for structural pattern matching, slots=True
class Comment:
    id:int
    txt:str
    replies: list[str] = field(default_factory=list)	# list or any other fn that generates initial value. Factory is invoked if user doesn't specify this field while creating object. Can set "init=False" in field() to ensure that user can not provide this arg. "repr=False" to hide field from printing with repr. "compare=False" to skip the field 
    				# __post__init__(self) method can be used to set attributes that depend on other member attrib.
    	

def main():
    comment = Comment(1,"hoo")
    print(comment)
    # comment.id=2
    # comment.set_id(2)
    # print(comment)
    comment.x = 100	# can't do if frozen
    print(comment.x)
    number, comment = astuple(comment)		# dataclass converts to tuple/dict

    pprint(inspect.getmembers(Comment, inspect.isfunction))


if __name__ == '__main__':
    main()
    

match statement (for structural pattern matching) from Py3.10. 
Can match single value (int/str) or other type like list/dict and other objects
Match patterns based on given sequence i.e. order is important.
	match var:
		case 0: pass
		case 1|2: pass
		case 3 if condition: pass	#  with if condition
		case 3: pass
		case _: pass
		case other: print("unknown")

Decorator:
	Enhance/Modify behavior to existing fn. E.g. add time taken by existing fn; add logging/user behavior; authentication before fn calls.
	Address cross-cutting concerns (impacts multiple fn).
	Decorator takes a fn as input and returns modified fn as output.
	Can have multiple decorator on fn. E.g. @logging @timer on fn
	Caution - decorator impacts readability/understanding of code. e.g. when multiple decorator are used. Which one kicks in first e.g. logging before timing or after.
	
	def my_decorator(func, logger):		# instead of using functools.partial you can create an another outer layer of fn that takes logger as arg and returns my_decorator (see https://stackoverflow.com/questions/5929107/decorators-with-parameters)
	  @functools.wraps(func)		# fixes func.__name__ not to print "wrapper" but actual fn. Fixes fn.docstring and fn.name
	  def wrapper(*args, **kwargs):
	    logger.info(f"Started function {func.__name__}")
	    ret = func(*args, **kwargs)
	    logger.info("Ended")
	    return ret
	  return wrapper
	  
	@my_decorator(logging)		# inc = decorator(logging)(inc)   ... this is what it means and it won't work here because my_decorator needs 2 args. Use functools.partial or wrap my_decorator in another fn lets call it decorator_generator(logger)
	def inc(x):
	  return x+1

	my_decorator_with_default_logging = functools.partial(my_decortor, logger=logging)
	
	@my_decorator_with_default_logging
	def dec(x):
	  return x-1
	  
	inc(3)


Functools: Fn/Operations on callables (Fn, Class, Obj)
	@cache - memoize - store return values for args
	@cache_property - cache for methods; note: @property requires a setter fn but @cache_property allows writes
	@lru_cache(maxsize=N, typed=False) - args/kwargs must be hashable. Implemented with @cache_property but slightly slower as it needs to handle max_size limits.
		- has additional data like cache_info() to show hits/misses/currsize.
		- typically for expensive/recursive compute e.g. fibonacci or news web-page fetch
	@total_ordering - adds le/ge/lt/gt methods based on 2 methods that user needs to give i.e. eq and one of le/ge/lt/gt
	@partial - simplifies fn args/kwards by pre-building partial fn object that has some args/kwargs supplied in advance so that partial fn is called with remaining args/kwargs. Similarly, @partialmethod for methods/property.
	@reduce - apply fn to iterable with a default start value e.g. sum of series
	@wraps - calls update_wrapper that updates wrapper fn to look like wrapped function. Assigns __module__, __name__, __doc__, __annotations__, __qualname__. Updates __dict__. Used with decorators specially
	@singledispatch - transform fn into single-dispatch generic fn (based on type of first arg only). Declare the default fn with @singledispatch and then register other variants based on type(s) with @fn.register(type). To check which fn will be called for a given type, test with fn.dispatch(type) .. gives address of fn (not name!).
	@singledispatchmethod - like singledispatch on methods but applies on first non-self/non-cls arg.

Itertools: Creates iterators for efficient looping
	- non-terminating/infinite iterators
		- count(start, [step]]: count() from 0/start onwards
		- cycle(list_elements): cycle('0123456789')  ... 0123456789 0123456789 0123456789
		- repeat(element, [n)]: repeat('xyx', 20)  ...xyz xyz
	- terminating on shortest input sequence:
		- accumulate(list, [func=sum]): accumulate([1,2,3], lambda x,y: x+y) gives 1,3,6 (get running totals/products)
		- chain(list1, list2): chain any 2 iterables one after another
		- chain.from_iterable(iterable): chain iterable of iterables
		- compress(data_list, selector_list_bool): removes elements marked as false in selector list
		- dropwhile(predicate, sequence): chopping leading sequence. i.e. predicate applied to "leading" sequence; drops leading sequence if initially predicate is true and once false, ignores predicate and generates till end of sequence.
		- filterfalse(predicate, sequence): opposite of filter(which keeps elements where predicate is true), this keeps elements where predicate is false
		- groupby(iterable, [key]): sub-iterators groups by value of key(v)
		- isslice(sequence, [start, stop, step]): like slice/range for sequence
		- pariwise(iterable): ABCD gives overlapping pairs of AB BC CD
		- starmap(function, sequence): gives sequence of fn(*seq[0]), fn(*seq[1]). i.e. fn args come from sequence (as sub-lists) and returns sequence of results
		- takewhile(predicate, sequence): opposite of dropwhile, it gives the leading sequence while predicate is true
		- tee(iterator, n): splits one iterator in N-iterators. Allows reuse/copy of iterator.
		- zip_longest(seqA, seqB, [fillValue='-']) gives tuple having first element from seqA and second frmo seqB. Any missing values are replaced with None/fillValue.
	- Combination/Permutations
		- product(seqA, seqB, [repeat=1]) Cartesion product
		- permutations(seq, length) all combinations but no repeats e.g. AA but can have AB and BA
		- combinations(seq, length) permutations but can't have AB == BA
		- combinations_with_replacement(seq, length) allows AA

Operator: efficient operator fn
	- le, ge, lt, gt, eq, ne
	- not, is_, is_not, truth (or bool)
	- abs(x), add, sub, mul, floordiv, truediv, index (convert non-int to int for use as index), inv/invert, mod (%), pow, matmul (@), pos (postivie),  
		-- in-place operators (x+=y is x= operator.iadd(x,y)). Returns updated value if inputs are immutable else updates in place.
		-- iadd/iconcat (a+=b), a&=b, a<<=b, a//=b, a@=b,
	- lshift, rshift,     neg, or_, and_, xor
	- concat, contains(a,b ... b in a), countOf, indexOf, get/set/delitem 
	- call
	- attrgetter & itergetter:
		-- f = attrgetter('name.first', 'name.last'), then call f(b) returns (b.name.first, b.name.last).
		-- g = itemgetter(2, 5, 3), the call g(r) returns (r[2], r[5], r[3]).
			getcount = itemgetter(1)
			sorted(inventory, key=getcount)
			# [('orange', 1), ('banana', 2), ('apple', 3), ('pear', 5)]

Collections
    defaultdict(factory)
    Counter(dist).most_common 

Coding exercises in various languages (incl Python) with solutions: https://rosettacode.org/wiki/Category:Python 
David Beazley - https://github.com/dabeaz/blog
