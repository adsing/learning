See code/python/pandas (Data manipulation + linear regresison)

Pandas :: Series (list of same type). pd.Series
          DataFrame (table of rows & columns with columns of same type). pd.DataFrame
             A dataframe is a collection of Series
Both Dataframe and Series have index.

import numpy as np
import pandas as pd
pd.set_option('display.max_rows', 5)

df = pd.DataFrame(data={'ColA': [100, 200], 'ColB': ['Bob','Sam'], 'ColC': [True, False],
                  index=['row0','row1']}     # index is list of rows which defaults to [0,1,..]
                  )
s = pd.Series([1,3,5,7,9], index=[0,1,2,3,4], name='Odd')

df.shape  # (rows, cols)
df.head()
df = pd.read_csv(filename, 
                index_col=0,  # file has index so use that column
                )
df.colA     # or df["colA"]   ... returns Series
df.iloc[0]  # index-based selection (row first, column second) ... gives first row
df.iloc[:,0] # all rows (start:end), first column only 
df.iloc[0:5, 0]     ## row 0 to 4 (5 excluded; python range-like excludes end)

df.loc[0:5, 0]      ## # row index 0 to 5 (not 4! ... differs from iloc), col 0 only
df.loc['row0']
df.loc[0:5, "colA"]  # df.loc[0:5, ["colA","colB"]  or df.loc[ [0,1,2] : [0,1,2] ] # 3 rows, 3 cols
# note: iloc index excludes ending range; while loc *includes* ending range (loc range can be non-numeric!). Also, iloc needs both row/index & columns in integer indices i.e. can't use column names

df.set_index('colB')

# condition & |
# colA.isin(...) colA.isnull() colA.notnull
df.loc[(df.colA == 'USA') & (df.colB == 'Chicago')]     # all cols for rows matching this condition

df.ColNew = 'Singular'
df.ColNew2 = range(len(df))

# url = github raw csv
tips = pd.read_csv(url)
tips.head()
# total_bill, tips, sex, smoker, day, time, size
#  ##.##       #.#  M/F   Y/N   Sat-Sun Lunch/Dinner 2,3,4

tips[['total_bill','tips','size','day']]
is_dinner = tips.Dinner == 'Dinner'
is_dinner.value_counts   # T ... F ...

# tip >= 5.00 and Dinner
tips[(tips.time == 'Dinner) & (tipss.tip >= 5.0)].head()

# where time is null with isnull/notnull
tips[tips.time.isnull()]

# aggregate/group-by.  SQL count->size; SQL avg->mean
## equivalent
tips.sex.value_counts()
tips.groupby('sex').size()
tips.groupby('sex')['total_bill'].count()
## multiple agg e.g. avg(tip), count()
tips.groupby('day').agg({'tip':np.mean, 'day':np.size})
tips.groupby(['day', smoker']).agg({'tip':np.mean, 'day':np.size})      # big daddy of above

# join -> merge
pd.merge(df1, df2, on='key_column')
pd.merge(df1, df2, left_on='left_key_column', right_index=True)     # column & index match
pd.merge(df1, df2, left_index=True, right_index=True)       # e.g. time series based data
pd.merge(df1, df2, left_on='left_key_column', right_index=True, how='left')     # left outer (left|right|inner|outer)

# union all -> concat
pd.concat([df1, df2, ...])
pd.concat([df1, df2]).drop_duplicates()         # SQL union to remove dups

# can also pick which col/index to stack unstack e.g. df.stack(1)
df.stack()  # make first column as last component of a multi-index
df.unstack() # makes last index of a multi-index as the first column
