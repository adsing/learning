JSON data - unstructured so more flexible
  Predictable structure makes it easier to query JSON

Postgres types:
- json (preserves whitespace and dups in keys)
- jsonb (binary representation of parsed JSON and does not preserve whitespace/dups in keys); limit to mapped postgres type e.g numeric limits

JSON -> Postgres type
====    =============
string  - text     (as single quote '...'  and not "...")   #double quote string refers to column name in postgres? TBD
numeric - numeric
boolean - boolean  (as true/false)
null    - (none)   (not NULL)
+ Arrays and objects/dicts (which have keys as strings) 

select '5':json;
select '[1, 2.0, true, null]'::jsonb;
select '{"k1":1,"k2":2.0,"k3":[true,false],"k4":null}'::jsonb;

Containment (@>) - nested!
select '[1,2,3]'::jsonb @> '3'::jsonb;
-- array on right is contained in array on left (ordering/dups insignificant)
select '[1,2,3]'::jsonb @> '[3,1,1]'::jsonb;
--nested array not checked unless right array is also nested 
select '[1,[2,3]]'::jsonb @> '[2,3]'::jsonb;   --false
select '[1,[2,3]]'::jsonb @> '[[2,3]]'::jsonb;
--same with nested objects
select '{"foo":{"a":"b"}}'::jsonb @> '{"a":"b"}'::jsonb;
select '{"foo":{"a":"b"}}'::jsonb @> '{"foo":{}}'::jsonb;   --top level key and empty object is contained

The general principle is that the contained object must match the containing object as to structure and data contents, possibly after discarding some non-matching array elements or object key/value pairs from the containing object. But remember that the order of array elements is not significant when doing a containment match, and duplicate array elements are effectively considered only once.
An array may contain primitives like string/numeric.

Existence (?)
Check if given string appears as object key or array element or primitive. Does not consider object values! So not nested.
--operator for integer ? does not exists
--select '[1,2,3,4]'::jsonb ? 2;
--select '[1,2,3,4]'::jsonb ? '2';
select '"foo"'::jsonb ? 'foo';
select '["foo","bar"]'::jsonb ? 'bar';
select '{"foo":"f","bar":"b"}'::jsonb ? 'bar';
select '{"foo":"f","bar":"b"}'::jsonb ? 'b';  --fail

JSON objects are better optimized for containment/existence than arrays.

-- example:
-- In json column docs, objects have "tags" key; search for tags key whose array values contain the objects {"term":"paris"} AND {"term":"food"}
SELECT doc->'site_name' FROM websites
  WHERE doc @> '{"tags":[{"term":"paris"}, {"term":"food"}]}';
OR
SELECT doc->'site_name' FROM websites
  WHERE doc->'tags' @> '[{"term":"paris"}, {"term":"food"}]';

GIN index:
CREATE INDEX idxgin ON Table USING GIN (column);      -- default : eff top level key search + existence (?,?&,?|) and path/value exists operator @>
CREATE INDEX idxgin ON Table USING GIN (column jsonb_path_ops);  --only @> but very performant & smaller sized (hash of keyys & values)
Also: BTREE and HASH index (used to check equality of JSON docs)

CREATE INDEX idxgin ON Table USING GIN ( (column->'tag') );  -- where column->'tag' ? 'someValue'; uses this index





https://docs.python.org/3/library/json.html 19.2

JSON lint (format check) - https://jsonlint.com/

Pretty print jason:: cat my.json | python3 -m json.tool  | pygmentize -l json    <https://stackoverflow.com/questions/12943819/how-to-prettyprint-a-json-file> 


Java Script Object Notation
Is subset of YAML 1.2
Data Interchange format that is language independent
Easy to read/write for humans & machines

Good for representing sparse data (e.g. hobbies of employees - DB support of JSON as column).

JSON built on 2 structures - object/dictionary (key:value) and arrays
Object: { key1 : value1 , key2 :  value2 }  #keys are stringified so json.loads( json.dumps(x) ) != x if non-string keys are present. Note: last element should not have a comma (python allows)
Array : [ val1, val2, … ]

Value is a "string", 'a', 123, true/false or null or object or array.
Numbers can't be hexadecimal or octal representation.
", \ are escaped.
Lose tuple read-only information (converted to array and back to list).

Watch for size & nesting levels of JSON files.
Large numbers may be represented in IEEE754 format causing loss of precision.

Conversion table:
Python	JSON
dict	object
list, tuple	array
str, unicode	string "…"
int, long, float	number
True	true
False	false
None	null
Non-JSON compliant changes	(allow_nan = True)
nan	NaN
Inf/-Inf	Infinity/-Infinity
Repeated object names	

From <https://docs.python.org/2/library/json.html#py-to-json-table> 



Python:
>>> import json
>>> json.dumps(['foo', {'bar': ('baz', None, 1.0, 2)}])
'["foo", {"bar": ["baz", null, 1.0, 2]}]'
>>> print(json.dumps({"c": 0, "b": 0, "a": 0}, sort_keys=True))
{"a": 0, "b": 0, "c": 0}
>>> json.dumps("\"foo\bar")
'"\\"foo\\bar"'
>>> 
From <https://docs.python.org/2/library/json.html> 

Specialized object -> dictionary -> binary with hooks to convert binary <=> object 

Specialized object decoding:
>>> import json
>>> def as_complex(dct):
...     if '__complex__' in dct:
...         return complex(dct['real'], dct['imag'])
...     return dct
...
>>> json.loads('{"__complex__": true, "real": 1, "imag": 2}', object_hook=as_complex)
(1+2j)
From <https://docs.python.org/2/library/json.html> 

Specialized object encoding:
>>> import json
>>> def encode_complex(obj):
...     if isinstance(obj, complex):
...         return [obj.real, obj.imag]
...     raise TypeError(repr(obj) + " is not JSON serializable")
>>> json.dumps(2 + 1j, default=encode_complex)
'[2.0, 1.0]'


SERIALIZE
json.dumps(obj)    #to string                separators = (',' , ':') for item and key sep.
json.dump(obj, fp) #to file pointer
DE-SERIALIZE
json.loads(str)  #to python object  from string              object_book=function that takes obj as dict …for custom decoders
json.load(fp)      #from file                                                  parse_int|float|constants like Infinity/NaN
                                                                                                supply a class (cls=myclass) that is subclass of json.Decoder

Use Decoder/Encoder to extend functionality for JSON to support user-defined class.

JSON.TOOL - pretty print + validate
$ echo " … " | python -m json.tool  --outfile /tmp/a --sort_keys
